---------------------------- Prac 1 ---------------------------------------------
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

data = pd.get_dummies(pd.read_csv("E:/sem2/practicals/bda/Wholesalecustomersdata.csv"), columns=['Channel', 'Region'])
data_scaled = MinMaxScaler().fit_transform(data)

plt.plot(range(1, 15), [KMeans(n_clusters=k).fit(data_scaled).inertia_ for k in range(1, 15)], 'r:*')
plt.xlabel('k')
plt.ylabel('Sum of Squared Distances')
plt.title('Elbow Method for Optimal k')
plt.show()



---------------------------- Prac 2 ----------------------------------------------
use Suyog
db.wordcount.insertOne({name:'Suyog Shah'})  
db.wordcount.insertOne({name:'Lionel Messi'})  
db.wordcount.insertOne({name:'Cristiano Ronaldo '})  
db.wordcount.insertOne({name:'Erling Haaland'})  
db.wordcount.insertOne({name:'Kylian Mbapp√©'})  
db.wordcount.insertOne({name:'David Beckham'})  
db.wordcount.insertOne({name:'Shubham Ghosalkar'})  
db.wordcount.insertOne({name:'David Silva'})  
db.wordcount.find()
var mapFunction=function(){  
var words=this.name.split(" ");  
for(var i=0;i<words.length;i++){  
emit(words[i],1);}}; 
var reduceFunction=function(key,values){  
var count=0  
for(var i=0;i<values.length;i++){  
count+=values[i];  
}  
return count;  
};
db.wordcount.mapReduce(mapFunction,reduceFunction,{out:"word"});  
db.word.find()

---------------------------- prac 3a-1 --------------------------------------------------------------
import pandas as pd
import numpy as np
from sklearn import linear_model
import matplotlib.pyplot as plt
print("Practical performed by Suyog Shah")
df = pd.read_csv(r"E:\sem2\practicals\bda\homeprices.csv")
print(df)
plt.scatter(df['area'], df['price'], color='red', marker='.', label='Actual Data')
plt.xlabel('Area (sq ft)')
plt.ylabel('Price')
X = df[['area']]
y = df['price']
model = linear_model.LinearRegression()
model.fit(X, y)
y_pred = model.predict(X)
plt.plot(df['area'], y_pred, color='blue', label='Best Fit Line')
plt.legend()
plt.show()
predicted_price = model.predict(pd.DataFrame({'area': [1500]}))
print("Predicted price for 1500 sq ft:", predicted_price[0])
print('Model Coefficient:', model.coef_[0])
print('Model Intercept:', model.intercept_)


--------------------------------------- prac 3a-2 --------------------------------------------------------------

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
data = pd.read_csv(r"E:/sem2/practicals/bda/weightwaist.csv - Sheet1.csv")
data.plot(kind='scatter', x='waist_cm', y='weight_kg')
plt.show()
print(data.corr())
waist, weight = data[['waist_cm']], data[['weight_kg']]
lm = LinearRegression().fit(waist, weight)
print(f"Model Coefficient: {lm.coef_}, Intercept: {lm.intercept_}, R^2: {lm.score(waist, weight)}")
Waist_new = pd.DataFrame({'waist_cm': [97]})
Weight_predict = lm.predict(Waist_new)
print(f"Predicted weight for waist 97cm: {Weight_predict}")
df = pd.DataFrame({'waist_cm': [67, 78, 94]})
df['Weight_predicted'] = lm.predict(df)
print(df)
data.plot(kind='scatter', x='waist_cm', y='weight_kg')
plt.plot(waist, lm.predict(waist), color='red', linewidth=2)
plt.scatter(Waist_new, Weight_predict, color='black')
plt.show()


---------------------- prac 3a-3 -----------------------------------------


import pandas as pd, matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
df = pd.read_csv("E:/sem2/practicals/bda/canada_per_capita_income.csv")
print(df)
plt.scatter(df['year'], df['per capita income (US$)'], color='green', marker='o')
plt.plot(df['year'], LinearRegression().fit(df[['year']], df['per capita income (US$)']).predict(df[['year']]), color='blue')
plt.xlabel('Year'); plt.ylabel('Per Capita Income (US$)'); plt.title('Canada Per Capita Income Over Years'); plt.show()
model = LinearRegression().fit(df[['year']], df['per capita income (US$)'])
print("Predicted income for 2025:", model.predict([[2025]])[0])
print("Model Coefficient:", model.coef_[0])
print("Model Intercept:", model.intercept_)
print("Model Score (R^2):", model.score(df[['year']], df['per capita income (US$)']))




----------------------prac 3b ------------------------------

import numpy as np
from matplotlib import pyplot as plt
from sklearn.linear_model import LogisticRegression 
from sklearn.model_selection import train_test_split 
from sklearn.metrics import confusion_matrix
from sklearn.datasets import make_classification
x, y = make classification(
    n_samples=100,
    n_features=1,
    n_classes=2,
    n_clusters_per_class=1,
    n_informative=1,
    n_redundant=0,
    n_repeated=0,
    random_state=s,
)
x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1)
log_reg = LogisticRegression()
log_reg.fit(x_train, y_train)
print("Coefficient (slope):", log_reg.coef_) 
print("Intercept (bias):", log_reg.intercept_)
y_pred= log_reg.predict(x_test)
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
x_values = np.linspace(x.min(), x.max(), 500).reshape(-1, 1)
y_prob = log_reg.predict_proba(x_values) [:, 1]
plt.scatter(x, y, c=y, cmap='plasma', label='Data points') # 'viridis', 'plasma', or 'coolwarm'. 
plt.plot(x_values, y_prob, color='black', label='Decision Boundary(Sigmoid Curve)')
plt.axhline(0.5, color='gray', linestyle='dotted', label= 'Threshold = 0.5')
plt.title("Logistic Regression Decision Boundary")
plt.xlabel('Feature')
plt.ylabel('Probability')
plt.legend() 
plt.show()


----------------------- prac 4a ---------------------------
momgo :---
db.Prac4A.insertOne({Name:'ShubhamGhosalkar',Class:'MScIT',Roll_N0
 1})  
db.Prac4A.insertOne({Name:'Shubham Gite',Class:'MScIT',Roll_No:2}) 
db.Prac4A.insertOne({Name:'Tejas Pednekar',Class:'MScIT',Roll_No:3})  
db.Prac4A.insertOne({Name:'Suyog Shah',Class:'MScIT',Roll_No:4})
db.Prac4A.insertOne({Name:'Yash Yadav',Class:'MScIT',Roll_No:5})  
db.Prac4A.find() 
db.Prac4A.find() 

py :--
from pymongo import MongoClient 
client=MongoClient('localhost:27017')
db=client.Suyog
collection=db.Prac4A
print("Whole Record: ")
for x in collection.find({},{"_id": 0, "Name": 1, "Class":1,"Roll_No":1}):
    print(x)
record={"Name": "ABC XYZ", "Class":"MSCIT", "Roll_No":"6"}
result=collection.insert_one(record)
print("inserted record id: ", result. inserted_id)
print("Updated Record: ")
for x in collection.find({},{"_id": 0, "Name": 1, "Class":1,"Roll_No":1}): 
    print(x)
filter={"Name":"ABC XYZ"}
update_record=("$set":{"Class":"BSCIT"}}
result=collection.update_one(filter, update_record)
print("Records Matched: ", result.matched_count)
print("Records Modified: ", result.modified_count) 
print("Updated Record: ")
for x in collection.find({},{"_id": 0, "Name": 1, "Class": 1, "Roll_No":1}):
    print (x)
filter={"Name":"ABC XYZ"}
result=collection.delete_one(filter)
print("Deleted record count: ", result.deleted_count)
print("Updated Record: ")
for x in collection.find({},{"_id": 0, "Name": 1, "Class": 1, "Roll_No":1})|:
    print (x)


--------------------- prac 4b ------------------------
mongo:- 
db.Prac4B.insertOne({Name:'ShubhamGhosalkar',Class:'MScIT',Roll_No:
 1})  
db.Prac4B.insertOne({Name:'Shubham Gite',Class:'MScIT',Roll_No:2}) 
db.Prac4B.insertOne({Name:'Tejas Pednekar',Class:'MScIT',Roll_No:3})  
db.Prac4B.insertOne({Name:'Suyog Shah',Class:'MScIT',Roll_No:4})  
db.Prac4B.insertOne({Name:'Yash Yadav',Class:'MScIT',Roll_No:5}) 
db.Prac4B.find()

py code :-
from pymongo import MongoClient
client=MongoClient ('localhost:27017')
db=client.Suyog
collection=db.Prac4B
print("Whole Record: ")
for x in collection.find({}, {"_id": 0, "Name": 1, "Class": 1, "Roll_No":1}): 
    print (x)
result=collection.insert_many([{"Name":"ABC XYZ", "Class": "MSCIT", "Roll_No":"6"},{"Name": "IJK LMN", "Class":"MSCIT", "Roll_No":"7"}]) 
print("inserted record id: ", result.inserted_ids)
print("Updated Record: ")
for x in collection.find({},{"_id": 0, "Name": 1, "Class": 1, "Roll_No":1}):
    print (x)
filter={"Name":"MSCIT"}
update_record=("$set":{"Qualification":"Graduated"}}
result=collection.update_many(filter, update_record) 
print("Records Matched: ", result.matched_count) 
print("Records Modified: ", result.modified_count) 
print("Updated Record: ")
for x in collection.find({}, {"_id":0,"Name": 1, "Class": 1, "Roll_No":1}): 
    print (x)
filter=({"Sor": [{"Roll_No":"6"},{"Roll_No": "7"}]}) 
result=collection.delete_many(filter)
print("Deleted record count: ", result.deleted_count) 
print("Updated Record: ")
for x in collection.find({}, {"_id": 0, "Name": 1, "Class": 1, "Roll_No":1}):
    print (x)



------------------------- prac 5 --------------------------------

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn import metrics

# Print statement
print("Practical performed by Suyog Shah")

# Input file path (fixed with forward slash)
InputFile = "E:/sem2/practicals/bda/social.csv"

# Read CSV file
df = pd.read_csv(InputFile)
print(df)

# Select features (x) and target (y)
x = df.iloc[:, [2, 3]]
y = df.iloc[:, 4]
print("x:\n", x)
print("y:\n", y)

# Split data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)
print("Training Data: \n", x_train)
print("Testing Data: \n", x_test)

# Feature scaling
sc_x = StandardScaler()
x_train = sc_x.fit_transform(x_train)
x_test = sc_x.transform(x_test)  # Use transform instead of fit_transform for test data

# SVM classifier with linear kernel
classifier = SVC(kernel='linear', random_state=0)
classifier.fit(x_train, y_train)

# Make predictions
y_pred = classifier.predict(x_test)
print("y_pred: \n", y_pred)

# Calculate accuracy
print("Accuracy Score with Linear Kernel: ")
print(metrics.accuracy_score(y_test, y_pred))



------------------------- prac 6 --------------------------------
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split

# Print statement
print("Practical performed by Suyog Shah")

# Read CSV file with corrected file path (forward slashes)
df = pd.read_csv("E:/sem2/practicals/bda/Social_Network_Ads.csv")
print(df)

# Selecting features (Age, EstimatedSalary) and target (Purchased)
X = df[["Age", "EstimatedSalary"]]
Y = df["Purchased"]

# Splitting data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)
print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)

# Feature scaling with MinMaxScaler
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Converting X_test_scaled into a DataFrame
X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=["Age", "EstimatedSalary"], index=X_test.index)

# Training Decision Tree Classifier
model_DT = DecisionTreeClassifier()
model_DT.fit(X_train_scaled, Y_train)

# Making predictions
Y_predict = model_DT.predict(X_test_scaled)

# Plotting the data points
plt.scatter(X_test_scaled_df[Y_test == 0]['Age'], X_test_scaled_df[Y_test == 0]['EstimatedSalary'], c='yellow', alpha=0.7, label="Not Purchased")
plt.scatter(X_test_scaled_df[Y_test == 1]['Age'], X_test_scaled_df[Y_test == 1]['EstimatedSalary'], c='green', alpha=0.7, label="Purchased")
plt.xlabel("Age (Scaled)")
plt.ylabel("Estimated Salary (Scaled)")
plt.legend()
plt.show()

# Displaying model accuracy
print("Model Accuracy:", model_DT.score(X_test_scaled, Y_test))

------------------------- prac 7 --------------------------------

from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd

print("Practical performed by Suyog Shah")

# Sample documents for TF-IDF transformation
documents = [
    "The car is fast",
    "The bike is slow",
    "The car is fast, bike is slow"
]

# Initialize the TF-IDF vectorizer
vectorizer = TfidfVectorizer()

# Transform the documents into a TF-IDF matrix
tfid_matrix = vectorizer.fit_transform(documents)

# Get the feature names (words)
feature_names = vectorizer.get_feature_names_out()

# Convert the TF-IDF matrix to an array
tfid_array = tfid_matrix.toarray()

# Create a DataFrame for better readability
df = pd.DataFrame(tfid_array, columns=feature_names)

# Print the DataFrame showing the TF-IDF values
print(df)

------------------------- prac 8 --------------------------------

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import nltk
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

print("Practical performed by Suyog Shah")

# Download necessary NLTK data
nltk.download('punkt')

# Read the dataset
Tweets_data = pd.read_csv("E:/sem2/practicals/bda/Tweets.csv")
print("Reading Data Set\n", Tweets_data.head(2), Tweets_data.shape)

# Pie chart for airline distribution
pie_plot1 = Tweets_data['airline'].value_counts()
pie_plot1.plot(kind="pie", autopct="%2.1f%%", startangle=90)
plt.title('Airline Distribution')
plt.show()
print('\n', pie_plot1.head(2))

# Pie chart for sentiment distribution
pie_plot2 = Tweets_data['airline_sentiment'].value_counts()
pie_plot2.plot(kind="pie", autopct="%2.1f%%", startangle=90)
plt.title('Sentiment Distribution')
plt.legend(pie_plot2.index, loc='best')
plt.show()
print("\n", pie_plot2.head(2))

# Prepare features and target variable
X = Tweets_data['text']
y = Tweets_data['airline_sentiment']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Vectorization
vectorizer = CountVectorizer()
X_train_vectorized = vectorizer.fit_transform(X_train)
X_test_vectorized = vectorizer.transform(X_test)

# Train the model
model = LogisticRegression(max_iter=1000)
model.fit(X_train_vectorized, y_train)

# Predictions
y_pred = model.predict(X_test_vectorized)

# Confusion matrix
cm = confusion_matrix(y_test, y_pred, labels=model.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()

# Accuracy
accuracy = np.mean(y_pred == y_test)
print(f'Accuracy: {accuracy:.2f}')

------------------------- prac 9 --------------------------------



------------------------- prac 10 --------------------------------


















